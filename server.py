import json
import base64
import cv2
import numpy as np
import logging
import gc
from datetime import datetime, timezone
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import config
import tensorflow as tf
import os
from face_recognition import FaceRecognitionSystem

# Táº¯t log khÃ´ng cáº§n thiáº¿t cá»§a TensorFlow
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"  # Táº¯t tá»‘i Æ°u hÃ³a CPU
os.environ["TF_LITE_DISABLE_XNNPACK"] = "1"  # VÃ´ hiá»‡u hÃ³a XNNPACK

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    tf.config.experimental.set_memory_growth(gpus[0], True)

# Thiáº¿t láº­p logging
logging.basicConfig(
    level=logging.INFO,  # Äáº·t má»©c log Ä‘á»ƒ debug
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# Khá»Ÿi táº¡o á»©ng dá»¥ng FastAPI
app = FastAPI(title="Face Recognition API")

# Cáº¥u hÃ¬nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Lazy Loading há»‡ thá»‘ng nháº­n diá»‡n khuÃ´n máº·t
face_system = None

def get_face_system():
    global face_system
    if face_system is None:
        logger.info("ğŸŸ¢ Khá»Ÿi táº¡o há»‡ thá»‘ng nháº­n diá»‡n khuÃ´n máº·t...")
        face_system = FaceRecognitionSystem(model_path="models/arcface_model.tflite", threshold=0.6)
        logger.info("âœ… Há»‡ thá»‘ng nháº­n diá»‡n khuÃ´n máº·t Ä‘Ã£ sáºµn sÃ ng")
    return face_system

# Káº¿t ná»‘i MongoDB
try:
    logger.info("ğŸ”„ Káº¿t ná»‘i Ä‘áº¿n MongoDB...")
    client = AsyncIOMotorClient(config.MONGO_URI)
    db = client["IoT"]
    faces_collection = db["face_embeddings"]
    logger.info("âœ… Káº¿t ná»‘i MongoDB thÃ nh cÃ´ng")
except Exception as e:
    logger.error(f"âŒ Lá»—i káº¿t ná»‘i MongoDB: {e}")
    raise

#Route kiá»ƒm tra tráº¡ng thÃ¡i server
@app.head("/")
async def reject_head():
    return {}

@app.get("/")
async def root():
    return {"message": "Welcome to the Face Recognition API!"}

@app.get("/health")
async def health_check():
    try:
        logger.info("ğŸ” Kiá»ƒm tra tráº¡ng thÃ¡i há»‡ thá»‘ng...")
        await db.command("ping")
        return {"status": "healthy", "database": "connected", "face_system": "running"}
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}")
        raise HTTPException(status_code=503, detail="Há»‡ thá»‘ng khÃ´ng kháº£ dá»¥ng")

def validate_image(image_data: str) -> bool:
    """Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a dá»¯ liá»‡u áº£nh."""
    if not image_data:
        return False
    try:
        base64.b64decode(image_data)
        return True
    except Exception:
        return False

def decode_image(image_data: str) -> np.ndarray:
    """Giáº£i mÃ£ dá»¯ liá»‡u áº£nh tá»« base64 sang numpy array."""
    try:
        img = base64.b64decode(image_data)
        np_arr = np.frombuffer(img, np.uint8)
        return cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
    except Exception as e:
        logger.error(f"âŒ Lá»—i giáº£i mÃ£ áº£nh: {e}")
        return None

async def handle_add_face(websocket: WebSocket, data: dict, image: np.ndarray):
    """Xá»­ lÃ½ yÃªu cáº§u Ä‘Äƒng kÃ½ khuÃ´n máº·t."""
    try:
        user_id = data.get("userID")
        if not user_id:
            raise ValueError("Thiáº¿u userID")
        logger.info(f"ğŸ‘¤ ÄÄƒng kÃ½ khuÃ´n máº·t má»›i cho userID: {user_id}")
        existing_face = await faces_collection.find_one({"userID": user_id})
        if existing_face:
            raise ValueError("UserID Ä‘Ã£ Ä‘Æ°á»£c Ä‘Äƒng kÃ½")

        embedding = get_face_system().get_embedding(image)
        if embedding is None:
            raise ValueError("KhÃ´ng thá»ƒ táº¡o embedding tá»« khuÃ´n máº·t")
        face_document = {"userID": user_id, "embeddings": embedding.tolist(), "created_at": datetime.now(timezone.utc)}
        await faces_collection.insert_one(face_document)
        logger.info("âœ… ÄÄƒng kÃ½ khuÃ´n máº·t thÃ nh cÃ´ng")
        await websocket.send_text(json.dumps({"type": "addFace", "status": "success"}))
    except ValueError as e:
        await websocket.send_text(json.dumps({"type": "addFace", "status": "fail", "message": str(e)}))
    except Exception as e:
        logger.error(f"âŒ Lá»—i Ä‘Äƒng kÃ½ khuÃ´n máº·t: {e}")
        await websocket.send_text(json.dumps({"type": "addFace", "status": "fail", "message": "ÄÄƒng kÃ½ khuÃ´n máº·t tháº¥t báº¡i", "messageFlow": "response"}))
    finally:
        gc.collect()

async def handle_recognize_face(websocket: WebSocket, data: dict, image: np.ndarray):
    """Xá»­ lÃ½ yÃªu cáº§u nháº­n dáº¡ng khuÃ´n máº·t."""
    try:
        logger.info("ğŸ” Báº¯t Ä‘áº§u nháº­n diá»‡n khuÃ´n máº·t...")
        embedding = get_face_system().get_embedding(image)
        if embedding is None:
            raise ValueError("KhÃ´ng thá»ƒ táº¡o embedding tá»« khuÃ´n máº·t")

        # Láº¥y táº¥t cáº£ embeddings tá»« MongoDB
        faces = await faces_collection.find().to_list(length=None)
        if not faces:
            raise ValueError("KhÃ´ng cÃ³ dá»¯ liá»‡u khuÃ´n máº·t trong há»‡ thá»‘ng")

        min_distance = float("inf")
        recognized_user = None

        for face in faces:
            stored_embedding = np.array(face["embeddings"], dtype=np.float32)
            distance = np.linalg.norm(embedding - stored_embedding)
            if distance < get_face_system().threshold and distance < min_distance:
                min_distance = distance
                recognized_user = face["userID"]

        if recognized_user:
            logger.info(f"âœ… Nháº­n diá»‡n thÃ nh cÃ´ng: {recognized_user}")
        else:
            logger.info("âŒ KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t phÃ¹ há»£p")
        await websocket.send_text(json.dumps({"type": "recognizeFace", "status": "success" if recognized_user else "fail", "userID": recognized_user}))
    except ValueError as e:
        await websocket.send_text(json.dumps({"type": "recognizeFace", "status": "fail", "message": str(e)}))
    except Exception as e:
        logger.error(f"âŒ Lá»—i nháº­n diá»‡n khuÃ´n máº·t: {e}")
        await websocket.send_text(json.dumps({"type": "recognizeFace", "status": "fail", "message": "Nháº­n diá»‡n khuÃ´n máº·t tháº¥t báº¡i", "messageFlow": "response"}))
    finally:
        gc.collect()


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """Xá»­ lÃ½ káº¿t ná»‘i WebSocket."""
    await websocket.accept()
    logger.info("ğŸ”— Káº¿t ná»‘i WebSocket má»›i")
    try:
        while True:
            message = await websocket.receive_text()
            data = json.loads(message)
            logger.info(f"ğŸ“© Nháº­n dá»¯ liá»‡u WebSocket: {data}")
            image = decode_image(data.get("image"))
            if data["type"] == "addFace":
                await handle_add_face(websocket, data, image)
            elif data["type"] == "recognizeFace":
                await handle_recognize_face(websocket, data, image)
            else:
                await websocket.send_text(json.dumps({"status": "fail", "message": "Loáº¡i yÃªu cáº§u khÃ´ng há»£p lá»‡"}))

    except WebSocketDisconnect:
        logger.info("ğŸ”Œ ÄÃ³ng káº¿t ná»‘i WebSocket")
    except Exception as e:
        logger.error(f"âŒ Lá»—i WebSocket: {e}")
    finally:
        logger.info(f"ğŸ”Œ ÄÃ³ng káº¿t ná»‘i tá»«: {websocket.client}")
        gc.collect()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, workers=1)