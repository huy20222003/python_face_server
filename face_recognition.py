import numpy as np
import logging
import os
import tensorflow as tf
import cv2
from typing import Optional
import mediapipe as mp

class FaceRecognitionSystem:
    def __init__(self, model_path: str = "models/arcface_model.tflite", threshold: float = 0.5):
        """
        Kh·ªüi t·∫°o h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t s·ª≠ d·ª•ng m√¥ h√¨nh TF Lite.
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n l∆∞u m√¥ h√¨nh TF Lite.
            threshold: Ng∆∞·ª°ng nh·∫≠n di·ªán.
        """
        self.threshold = threshold
        self.model_path = model_path
        self.model = None  # B·ªô nh·ªõ ƒë·ªám cho m√¥ h√¨nh TF Lite
        self.interpreter = None
        self.input_details = None
        self.output_details = None
        self._setup_logging()
        self._load_model()
        self.face_detector = mp.solutions.face_detection.FaceDetection(min_detection_confidence=0.5)
        
    def _detect_face(self, image: np.ndarray) -> Optional[np.ndarray]:
        """
        Ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh v√† tr·∫£ v·ªÅ v√πng ch·ª©a khu√¥n m·∫∑t l·ªõn nh·∫•t.
        """
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_detector.process(image_rgb)

        if results.detections:
            h, w, _ = image.shape
            max_area = 0
            best_face = None

            for detection in results.detections:
                bbox = detection.location_data.relative_bounding_box
                x, y, width, height = (
                    int(bbox.xmin * w), int(bbox.ymin * h),
                    int(bbox.width * w), int(bbox.height * h)
                )

                if width * height > max_area:
                    max_area = width * height
                    best_face = (x, y, width, height)

            if best_face:
                x, y, width, height = best_face
                x, y = max(0, x), max(0, y)  # ƒê·∫£m b·∫£o kh√¥ng b·ªã l·ªói c·∫Øt ·∫£nh
                return image[y:y + height, x:x + width]

        return None


    def _setup_logging(self) -> None:
        """C·∫•u h√¨nh logging."""
        logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
        self.logger = logging.getLogger(__name__)

    def _load_model(self) -> None:
        """T·∫£i m√¥ h√¨nh TF Lite v√†o b·ªô nh·ªõ n·∫øu ch∆∞a ƒë∆∞·ª£c t·∫£i."""
        if self.model is None:
            if not os.path.exists(self.model_path):
                self.logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i {self.model_path}.")
                raise FileNotFoundError("M√¥ h√¨nh kh√¥ng t·ªìn t·∫°i!")
            try:
                self.logger.info("üîÑ ƒêang t·∫£i m√¥ h√¨nh TensorFlow Lite v√†o b·ªô nh·ªõ...")
                self.interpreter = tf.lite.Interpreter(model_path=self.model_path)
                self.interpreter.allocate_tensors()
                self.input_details = self.interpreter.get_input_details()
                self.output_details = self.interpreter.get_output_details()
                self.logger.info("‚úÖ M√¥ h√¨nh TensorFlow Lite ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
            except Exception as e:
                self.logger.error(f"‚ùå L·ªói t·∫£i m√¥ h√¨nh: {e}")
                raise

    def _preprocess_image(self, image: np.ndarray) -> Optional[np.ndarray]:
        """
        Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o tr∆∞·ªõc khi ƒë∆∞a v√†o m√¥ h√¨nh.
        """
        try:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if image.shape[2] == 3 else image
            input_size = self.input_details[0]['shape'][1:3]  # L·∫•y k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o t·ª´ m√¥ h√¨nh
            image = cv2.resize(image, tuple(input_size))
            image = image.astype(np.float32) / 255.0  # Chu·∫©n h√≥a v·ªÅ kho·∫£ng [0,1]
            return np.expand_dims(image, axis=0)
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói x·ª≠ l√Ω ·∫£nh: {e}")
            return None

    def get_embedding(self, image: np.ndarray) -> Optional[np.ndarray]:
        """
        Tr√≠ch xu·∫•t embedding t·ª´ khu√¥n m·∫∑t s·ª≠ d·ª•ng m√¥ h√¨nh TF Lite.
        """
        face_image = self._detect_face(image)
        if face_image is None:
            self.logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh.")
            return None

        preprocessed_image = self._preprocess_image(face_image)
        if preprocessed_image is None:
            return None

        try:
            self.interpreter.set_tensor(self.input_details[0]['index'], preprocessed_image)
            self.interpreter.invoke()
            embedding = self.interpreter.get_tensor(self.output_details[0]['index'])[0]
            return embedding / np.linalg.norm(embedding)  # Chu·∫©n h√≥a embedding
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói tr√≠ch xu·∫•t embedding: {e}")
            return None

    def compare_faces(self, embedding1: Optional[np.ndarray], embedding2: Optional[np.ndarray]) -> bool:
        """So s√°nh hai embeddings ƒë·ªÉ x√°c th·ª±c khu√¥n m·∫∑t."""
        try:
            if embedding1 is None or embedding2 is None:
                return False
            similarity = np.dot(embedding1, embedding2)
            return similarity > self.threshold
        except Exception as e:
            self.logger.error(f"‚ùå L·ªói so s√°nh khu√¥n m·∫∑t: {e}")
            return False